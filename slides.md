---
title: Prompt Engineering â€“ GuÃ­a PrÃ¡ctica para Equipos TÃ©cnicos
author: GermÃ¡n Aliprandi
theme: geist
transition: slide-left
colorSchema: light
canvasWidth: 1280

defaults:
  layout: cover
  transition: fade

seoMeta:
  ogTitle: "Prompt Engineering â€“ GuÃ­a PrÃ¡ctica para Equipos TÃ©cnicos"
  ogDescription: "Esta guÃ­a presenta tÃ©cnicas y frameworks para optimizar la interacciÃ³n con Modelos de Lenguaje (LLMs) en entornos de desarrollo."
  ogUrl: "https://galiprandi.github.io/prompt-engineering/"

  class: "text-center"
  layout: center
---

# Prompt Engineering
## GuÃ­a PrÃ¡ctica

Esta guÃ­a presenta tÃ©cnicas y frameworks para optimizar la interacciÃ³n con Modelos de Lenguaje (LLMs) en entornos de desarrollo.

<div class="abs-br m-6 text-lg">
  <a href="https://galiprandi.github.io/me" target="_blank">GermÃ¡n Aliprandi</a> | Licencia MIT
</div>


---

## Temario

**1. Fundamentos y Principios Clave:** Impacto del prompt, anatomÃ­a de un LLM y buenas prÃ¡cticas.

**2. TÃ©cnicas de Prompting Esenciales:** Zero-shot, Few-shot, Chain-of-Thought, RAG, Multimodal & Tool-augmented y Incremental Prompting.

**3. Framework CRTR:** Estructura, beneficios y ejemplos prÃ¡cticos.

**4. Recursos:** Plantillas, lecturas y herramientas Ãºtiles.



---

## El Prompt como Vector de OptimizaciÃ³n

La calidad del prompt es el principal mecanismo de control sobre el rendimiento, el coste y la fiabilidad de un sistema basado en LLMs.

### Beneficios

**1. ReducciÃ³n de AmbigÃ¼edad**
Mejora precisiÃ³n y consistencia de las respuestas.

**2. Eficiencia de Recursos**
Menor consumo de tokens â†’ menor coste y latencia.

**3. MitigaciÃ³n de Riesgos**
Primera lÃ­nea de defensa contra alucinaciones y *outputs* inesperados.

**4. EstandarizaciÃ³n y Escalabilidad**
Permite crear prompts reutilizables, versionados y fÃ¡ciles de mantener.


---

## CÃ³mo â€œpiensaâ€ un LLM

Un LLM no â€œentiendeâ€ el lenguaje; es un motor de predicciÃ³n que sigue un proceso matemÃ¡tico para generar el siguiente token mÃ¡s probable. Tu prompt es el punto de partida de este ciclo:

**1. TokenizaciÃ³n:** El prompt se descompone en piezas (tokens).  
`"Resume este texto"` â†’ `["Resume", "este", "texto"]`

**2. Embeddings (Vectores SemÃ¡nticos):** Cada token se convierte en un vector numÃ©rico que captura su significado y relaciÃ³n con otros.

**3. Capas de AtenciÃ³n (Self-Attention):** El modelo pondera la importancia de cada token del contexto para decidir dÃ³nde "enfocar" su cÃ¡lculo.

**4. PredicciÃ³n (DistribuciÃ³n de Probabilidad):** Calcula la probabilidad de cada palabra posible en su vocabulario para ser el siguiente token.

**5. GeneraciÃ³n y Bucle:** Elige el token mÃ¡s probable, lo aÃ±ade a la secuencia y repite todo el proceso hasta generar la respuesta completa.

#### ğŸ§  *Tu prompt es el director de orquesta:* cada palabra que aÃ±ades o ajustas es una palanca para dirigir la *atenciÃ³n* del modelo y, por tanto, el resultado final.

---

## Â¿CÃ³mo influye el prompt en la inferencia?

El prompt es la palanca que ajusta el motor de **inferencia del LLM en tiempo real**. AsÃ­ es como cada palabra que escribes **moldea el resultado**:

**1. Condicionamiento del Contexto:**
Cada token de tu prompt se convierte en un vector que establece el punto de partida para el mecanismo de atenciÃ³n.

**2. DirecciÃ³n del Foco de AtenciÃ³n:**
Al aÃ±adir instrucciones, ejemplos o un rol, le das "pistas" al modelo sobre quÃ© tokens son mÃ¡s importantes, guiando su foco.

**3. ModificaciÃ³n de la Probabilidad:**
El resultado de la atenciÃ³n altera la distribuciÃ³n de probabilidad para el siguiente token. Un prompt especÃ­fico "afila" esta distribuciÃ³n, haciendo que la respuesta deseada sea mucho mÃ¡s probable.

**4. Control sin Re-entrenamiento:**
Logras controlar la salida del modelo de forma precisa **sin necesidad de modificar sus pesos internos**, todo ocurre durante la inferencia.


---

## Buen Prompt vs Mal Prompt

No todos los prompts son iguales. PequeÃ±os cambios pueden transformar la calidad de las respuestas.

| Prompt flojo | Prompt afinado |
|--------------|----------------|
| â€œResume este texto.â€ | â€œEres editor tÃ©cnico. Resume en â‰¤150 palabras, sin jerga, en espaÃ±ol neutro, destacando argumentos clave y conclusiones.â€ |

âœ… **Un buen prompt define rol, contexto, lÃ­mites y tono.**

âŒ **Un prompt vago deja demasiadas decisiones al modelo.**

---

## TÃ©cnica 1: Zero-shot / Few-shot

### Zero-shot
âœ… El modelo responde usando solo su conocimiento general, sin ejemplos especÃ­ficos.  

### Few-shot
âœ… Incluye 1-5 ejemplos para mostrar al modelo el estilo, formato o nivel de detalle deseado.  

**Ejemplo Few-shot**

```text
Eres Chat Bot de soporte.

Ejemplo â†’
Usuario: Â¿Diferencia entre `interface` y `type` en TypeScript?
Bot: Tanto `interface` como `type` definen formas, peroâ€¦

Nueva pregunta â†’
Usuario: Â¿Para quÃ© sirve `Partial<T>`?
Bot:
```

---

## TÃ©cnica 2: Chain-of-Thought (CoT)

âœ”ï¸ â€œPiensa paso a pasoâ€ obliga al modelo a explicitar su razonamiento.  

âœ”ï¸ Mejora precisiÃ³n en tareas complejas o con varios pasos.  

Variantes avanzadas: *Self-Consistency*, *Tree of Thoughts*.

**Ejemplo**

```text
Pregunta: Â¿CuÃ¡l es la complejidad media de `quickSort`?  
RazonÃ¡ paso a paso y, al final, responde en una sola lÃ­nea.
```

---

# TÃ©cnica 3: Role / Persona

âœ”ï¸ Define quiÃ©n â€œhablaâ€: mentor, abogado, tester, etc.  

âœ”ï¸ Establece contexto y tono coherente.  

âœ”ï¸ Mejora consistencia y relevancia de la respuesta.

**Ejemplo**

```text
Eres mentor senior de TypeScript.  
Explica a un junior por quÃ© conviene usar `unknown` en lugar de `any`.
```

---

# TÃ©cnica 4: Retrieval-Augmented Generation (RAG)

âœ”ï¸ Integra fragmentos de documentos externos para respuestas precisas y actualizadas.  

âœ”ï¸ Ideal para FAQs, bases de conocimiento y documentaciÃ³n interna.  

âœ”ï¸ Reduce alucinaciones al apoyar respuestas en datos verificables.

**Ejemplo**

```text
Contexto:  
â€¢ docs/api-auth.md (lÃ­neas 10-30)  
â€¢ README.md (lÃ­neas 55-60)  

Pregunta: Â¿CÃ³mo cambio el token de refresh?
```

---

# TÃ©cnica 5: Multimodal & Tool-augmented

<br/>

âœ”ï¸ Combina texto, imÃ¡genes y llamadas a funciones (`function calling`).  

âœ”ï¸ Ãštil para ejecutar cÃ³digo, analizar diagramas o integrar herramientas externas.  

âœ”ï¸ AmplÃ­a las capacidades del LLM mÃ¡s allÃ¡ del texto plano.

**Ejemplo**

```json
{
  "role": "system",
  "content": "Tienes la funciÃ³n runTests()"
}
```

---

# TÃ©cnica 6: Incremental Prompting

Consiste en **dividir un problema complejo en pasos pequeÃ±os**, usando prompts en secuencia donde cada resultado alimenta al siguiente.

**Beneficios clave:**

âœ”ï¸ Mejora la precisiÃ³n en tareas complejas.

âœ”ï¸ Reduce errores de contexto.

âœ”ï¸ Permite un control granular del proceso.

**Ejemplo (TraducciÃ³n + Resumen):**

1.  **Prompt 1 (Traducir):** `Traduce: â€œLa IA estÃ¡ transformando las empresas.â€`
    â†’ `AI is transforming businesses.`
2.  **Prompt 2 (Resumir):** `Resume el texto anterior en una frase.`
    â†’ `AI is changing business.`

**Aplicaciones:**

âœ”ï¸ Procesamiento de textos largos.

âœ”ï¸ GeneraciÃ³n de cÃ³digo paso a paso.

âœ”ï¸ Razonamiento complejo.

---

# Framework CRTR â€“ DefiniciÃ³n

El framework CRTR es una metodologÃ­a sistemÃ¡tica para estructurar prompts de manera clara y escalable.  
Divide el prompt en cuatro bloques esenciales que ayudan a reducir ambigÃ¼edad y facilitar la reutilizaciÃ³n:  
Contexto (quÃ© sabe la IA), Rol (quiÃ©n responde), Tarea (quÃ© debe hacer) y Resultado (cÃ³mo se presenta la salida).  
Esto permite crear prompts mantenibles y auditables en equipos tÃ©cnicos.

| Bloque          | Contenido                  | Pregunta clave              |
|-----------------|----------------------------|----------------------------|
| **C â€“ Context** | InformaciÃ³n relevante      | Â¿QuÃ© debe saber la IA?     |
| **R â€“ Role**    | Identidad o perspectiva    | Â¿QuiÃ©n estÃ¡ respondiendo?  |
| **T â€“ Task**    | AcciÃ³n solicitada          | Â¿QuÃ© debe hacer la IA?     |
| **R â€“ Result**  | Formato y limitaciones     | Â¿CÃ³mo quiero la salida?    |

---

# Beneficios del Framework CRTR

âœ”ï¸ Reduce ambigÃ¼edad, mejorando la calidad de las respuestas.  

âœ”ï¸ Facilita la creaciÃ³n de plantillas reutilizables por todo el equipo.  

âœ”ï¸ Permite versionar y auditar prompts de forma sencilla.  

âœ”ï¸ Escala bien en proyectos complejos con mÃºltiples casos de uso.

âœ”ï¸ Facilita el debugging de prompts: Si una respuesta es incorrecta, puedes aislar el problema. Â¿FallÃ³ el Contexto? Â¿El Rol es ambiguo? Â¿La Tarea es imprecisa?

Estas ventajas hacen que CRTR sea ideal para equipos tÃ©cnicos que buscan mantener consistencia y eficiencia en sus interacciones con LLMs.

---

# CRTR â€“ Ejemplo 1

Este ejemplo muestra cÃ³mo estructurar un prompt para redactar documentaciÃ³n tÃ©cnica clara y precisa.  
Definimos el contexto para situar al modelo, el rol para darle la perspectiva adecuada, la tarea especÃ­fica y el formato esperado para el resultado.  
Esto garantiza respuestas consistentes y alineadas con el objetivo.

```text
Context: Manual â€œAPI-Pagos v2.3â€.  
Role: Redactor tÃ©cnico senior.  
Task: Redacta la secciÃ³n â€œAutenticaciÃ³nâ€.  
Result: Markdown, â‰¤200 palabras, diagrama ASCII.
```

---

# CRTR â€“ Ejemplo 2

Este prompt estÃ¡ diseÃ±ado para comunicar resultados de un sprint de forma clara y motivadora.  
Se especifica el contexto del proyecto, el rol del emisor y la tarea de crear un anuncio con un tono apropiado, limitando la extensiÃ³n para mantenerlo conciso y efectivo.

```text
Context: Sprint 5 finalizado; hitos: OAuth, 95% tests verdes.  
Role: Product Owner.  
Task: Publicar anuncio interno de 4 pÃ¡rrafos.  
Result: â‰¤180 palabras, tono motivador, emojis moderados.
```

---

# CRTR â€“ Ejemplo 3

Este prompt estructura la descripciÃ³n de un Pull Request para facilitar la revisiÃ³n y auditorÃ­a.  
Incluye contexto tÃ©cnico, rol del revisor, tarea concreta y formato detallado, ayudando a que la informaciÃ³n crÃ­tica sea clara y organizada.

```text
Context: MigraciÃ³n de â€œuser-authâ€ a TS 5.5 estricto.  
Role: Revisor/a Front-End principal.  
Task: Redactar descripciÃ³n de Pull Request incluyendo riesgos y pruebas.  
Result: Markdown con secciones: Contexto, Cambios, Pruebas, Checklist QA.
```

---

# CRTR â€“ Recursos

- Plantilla rÃ¡pida:

```text
Context: â€¦  
Role: â€¦  
Task: â€¦  
Result: â€¦
````

* [Prompt Engineering Guide](https://learnprompting.org/docs/introduction)
  GuÃ­a completa para entender y construir prompts efectivos.

* [DAIR AI â€“ Prompt Engineering Guide](https://dair.ai/projects/prompt-engineering/)
  Recurso detallado con tÃ©cnicas y mejores prÃ¡cticas para prompt engineering.

* [GPT-4.1 Prompting Guide](https://cookbook.openai.com/examples/gpt4-1_prompting_guide)
  ColecciÃ³n de ejemplos y consejos oficiales para mejorar la interacciÃ³n con modelos OpenAI.

* [Prompt engineering overview](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
  IntroducciÃ³n a tÃ©cnicas de prompting aplicado a desarrolladores.


---
layout: center
class: "text-center"
---

# Â¡Gracias!

### Hablemos de IA y desarrollo

**GermÃ¡n Aliprandi**

<div class="flex justify-center items-center space-x-4 mt-4">
  <a href="https://linkedin.com/in/galiprandi" target="_blank" class="flex items-center space-x-2">
    <span>ğŸ”— LinkedIn</span>
  </a>
  <a href="https://github.com/galiprandi" target="_blank" class="flex items-center space-x-2">
    <carbon-logo-github />  GitHub
  </a>
</div>

<div class="mt-8">
  <p>Escanea para ver esta presentaciÃ³n online</p>
  <img src="https://api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://galiprandi.github.io/prompt-engineering/" alt="QR Code" class="mx-auto" />
</div>
