---
title: Prompt Engineering ‚Äì Gu√≠a Pr√°ctica para Equipos T√©cnicos
author: Germ√°n Aliprandi
date: "3 Jul 2024"
theme: geist
transition: slide-left
colorSchema: light
canvasWidth: 1280

defaults:
  layout: default
  transition: fade
  
---


# Prompt Engineering

### Gu√≠a Pr√°ctica

Esta gu√≠a presenta t√©cnicas y frameworks para optimizar la interacci√≥n con Modelos de Lenguaje (LLMs) en entornos de desarrollo.

‚úçÔ∏è Autor: [Germ√°n Aliprandi](https://galiprandi.github.io/me/)

‚öñÔ∏è Licencia: [MIT](https://opensource.org/licenses/MIT)


---


# Agenda

**1. Fundamentos y Principios Clave**
   - Impacto del prompt, anatom√≠a de un LLM y buenas pr√°cticas.

**2. T√©cnicas de Prompting Esenciales**
   - Zero-shot, Few-shot, Chain-of-Thought, RAG y m√°s.

**3. Framework CRTR para Escalabilidad**
   - Estructura, beneficios y ejemplos pr√°cticos.

**4. Recursos y Siguientes Pasos**
   - Plantillas, lecturas y herramientas √∫tiles.



---

# El Prompt como Vector de Optimizaci√≥n

La calidad del prompt es el principal mecanismo de control sobre el rendimiento, el coste y la fiabilidad de un sistema basado en LLMs.

### Beneficios

**1. Reducci√≥n de Ambig√ºedad**
Mejora precisi√≥n y consistencia de las respuestas.

**2. Eficiencia de Recursos**
Menor consumo de tokens ‚Üí menor coste y latencia.

**3. Mitigaci√≥n de Riesgos**
Primera l√≠nea de defensa contra alucinaciones y *outputs* inesperados.

**4. Estandarizaci√≥n y Escalabilidad**
Permite crear prompts reutilizables, versionados y f√°ciles de mantener.


---

# C√≥mo ‚Äúpiensa‚Äù un LLM

Un LLM no ‚Äúentiende‚Äù el lenguaje; es un motor de predicci√≥n que sigue un proceso matem√°tico para generar el siguiente token m√°s probable. Tu prompt es el punto de partida de este ciclo:

**1. Tokenizaci√≥n**  
El prompt se descompone en piezas (tokens).  
`"Resume este texto"` ‚Üí `["Resume", "este", "texto"]`

**2. Embeddings (Vectores Sem√°nticos)**  
Cada token se convierte en un vector num√©rico que captura su significado y relaci√≥n con otros.

**3. Capas de Atenci√≥n (Self-Attention)**  
El modelo pondera la importancia de cada token del contexto para decidir d√≥nde "enfocar" su c√°lculo.

**4. Predicci√≥n (Distribuci√≥n de Probabilidad)**  
Calcula la probabilidad de cada palabra posible en su vocabulario para ser el siguiente token.

**5. Generaci√≥n y Bucle**  
Elige el token m√°s probable, lo a√±ade a la secuencia y repite todo el proceso hasta generar la respuesta completa.

<hr/>

üß† **Tu prompt es el director de orquesta:** cada palabra que a√±ades o ajustas es una palanca para dirigir la <strong>atenci√≥n</strong> del modelo y, por tanto, el resultado final.

---

## ¬øC√≥mo influye el prompt en la inferencia?

El prompt es la palanca que ajusta el motor de inferencia del LLM en tiempo real. As√≠ es como cada palabra que escribes moldea el resultado:

**1. Condicionamiento del Contexto:**
Cada token de tu prompt se convierte en un vector que establece el punto de partida para el mecanismo de atenci√≥n.

**2. Direcci√≥n del Foco de Atenci√≥n:**
Al a√±adir instrucciones, ejemplos o un rol, le das "pistas" al modelo sobre qu√© tokens son m√°s importantes, guiando su foco.

**3. Modificaci√≥n de la Probabilidad:**
El resultado de la atenci√≥n altera la distribuci√≥n de probabilidad para el siguiente token. Un prompt espec√≠fico "afila" esta distribuci√≥n, haciendo que la respuesta deseada sea mucho m√°s probable.

**4. Control sin Re-entrenamiento:**
Logras controlar la salida del modelo de forma precisa **sin necesidad de modificar sus pesos internos**, todo ocurre durante la inferencia.


---

# Buen Prompt vs Mal Prompt

No todos los prompts son iguales. Peque√±os cambios pueden transformar la calidad de las respuestas.

| Prompt flojo | Prompt afinado |
|--------------|----------------|
| ‚ÄúResume este texto.‚Äù | ‚ÄúEres editor t√©cnico. Resume en ‚â§150 palabras, sin jerga, en espa√±ol neutro, destacando argumentos clave y conclusiones.‚Äù |

‚úÖ **Un buen prompt define rol, contexto, l√≠mites y tono.**

‚ùå **Un prompt vago deja demasiadas decisiones al modelo.**

---

# T√©cnica 1: Zero-shot / Few-shot

### Zero-shot
‚úÖ El modelo responde usando solo su conocimiento general, sin ejemplos espec√≠ficos.  

### Few-shot
‚úÖ Incluye 1-5 ejemplos para mostrar al modelo el estilo, formato o nivel de detalle deseado.  

**Ejemplo Few-shot**

```text
Eres Chat Bot de soporte.

Ejemplo ‚Üí
Usuario: ¬øDiferencia entre `interface` y `type` en TypeScript?
Bot: Tanto `interface` como `type` definen formas, pero‚Ä¶

Nueva pregunta ‚Üí
Usuario: ¬øPara qu√© sirve `Partial<T>`?
Bot:
```

---

# T√©cnica 2: Chain-of-Thought (CoT)

- ‚ÄúPiensa paso a paso‚Äù obliga al modelo a explicitar su razonamiento.  
- Mejora precisi√≥n en tareas complejas o con varios pasos.  
- Variantes avanzadas: *Self-Consistency*, *Tree of Thoughts*.

**Ejemplo**

```text
Pregunta: ¬øCu√°l es la complejidad media de `quickSort`?  
Razon√° paso a paso y, al final, responde en una sola l√≠nea.
```

---

# T√©cnica 3: Role / Persona

- Define qui√©n ‚Äúhabla‚Äù: mentor, abogado, tester, etc.  
- Establece contexto y tono coherente.  
- Mejora consistencia y relevancia de la respuesta.

**Ejemplo**

```text
Eres mentor senior de TypeScript.  
Explica a un junior por qu√© conviene usar `unknown` en lugar de `any`.
```

---

# T√©cnica 4: Retrieval-Augmented Generation (RAG)

- Integra fragmentos de documentos externos para respuestas precisas y actualizadas.  
- Ideal para FAQs, bases de conocimiento y documentaci√≥n interna.  
- Reduce alucinaciones al apoyar respuestas en datos verificables.

**Ejemplo**

```text
Contexto:  
‚Ä¢ docs/api-auth.md (l√≠neas 10-30)  
‚Ä¢ README.md (l√≠neas 55-60)  

Pregunta: ¬øC√≥mo cambio el token de refresh?
```

---

# T√©cnica 5: Multimodal & Tool-augmented

- Combina texto, im√°genes y llamadas a funciones (`function calling`).  
- √ötil para ejecutar c√≥digo, analizar diagramas o integrar herramientas externas.  
- Ampl√≠a las capacidades del LLM m√°s all√° del texto plano.

**Ejemplo**

```json
{
  "role": "system",
  "content": "Tienes la funci√≥n runTests()"
}
```

---

# Framework CRTR ‚Äì Definici√≥n

El framework CRTR es una metodolog√≠a sistem√°tica para estructurar prompts de manera clara y escalable.  
Divide el prompt en cuatro bloques esenciales que ayudan a reducir ambig√ºedad y facilitar la reutilizaci√≥n:  
Contexto (qu√© sabe la IA), Rol (qui√©n responde), Tarea (qu√© debe hacer) y Resultado (c√≥mo se presenta la salida).  
Esto permite crear prompts mantenibles y auditables en equipos t√©cnicos.

| Bloque          | Contenido                  | Pregunta clave              |
|-----------------|----------------------------|----------------------------|
| **C ‚Äì Context** | Informaci√≥n relevante      | ¬øQu√© debe saber la IA?     |
| **R ‚Äì Role**    | Identidad o perspectiva    | ¬øQui√©n est√° respondiendo?  |
| **T ‚Äì Task**    | Acci√≥n solicitada          | ¬øQu√© debe hacer la IA?     |
| **R ‚Äì Result**  | Formato y limitaciones     | ¬øC√≥mo quiero la salida?    |

---

## Beneficios del Framework CRTR

- üéØ Reduce ambig√ºedad, mejorando la calidad de las respuestas.  
- üîÑ Facilita la creaci√≥n de plantillas reutilizables por todo el equipo.  
- üìö Permite versionar y auditar prompts de forma sencilla.  
- üöÄ Escala bien en proyectos complejos con m√∫ltiples casos de uso.
- üêõ Facilita el debugging de prompts: Si una respuesta es incorrecta, puedes aislar el problema. ¬øFall√≥ el Contexto? ¬øEl Rol es ambiguo? ¬øLa Tarea es imprecisa?

Estas ventajas hacen que CRTR sea ideal para equipos t√©cnicos que buscan mantener consistencia y eficiencia en sus interacciones con LLMs.

---

# CRTR ‚Äì Ejemplo 1

Este ejemplo muestra c√≥mo estructurar un prompt para redactar documentaci√≥n t√©cnica clara y precisa.  
Definimos el contexto para situar al modelo, el rol para darle la perspectiva adecuada, la tarea espec√≠fica y el formato esperado para el resultado.  
Esto garantiza respuestas consistentes y alineadas con el objetivo.

```text
Context: Manual ‚ÄúAPI-Pagos v2.3‚Äù.  
Role: Redactor t√©cnico senior.  
Task: Redacta la secci√≥n ‚ÄúAutenticaci√≥n‚Äù.  
Result: Markdown, ‚â§200 palabras, diagrama ASCII.
```

---

# CRTR ‚Äì Ejemplo 2

Este prompt est√° dise√±ado para comunicar resultados de un sprint de forma clara y motivadora.  
Se especifica el contexto del proyecto, el rol del emisor y la tarea de crear un anuncio con un tono apropiado, limitando la extensi√≥n para mantenerlo conciso y efectivo.

```text
Context: Sprint 5 finalizado; hitos: OAuth, 95% tests verdes.  
Role: Product Owner.  
Task: Publicar anuncio interno de 4 p√°rrafos.  
Result: ‚â§180 palabras, tono motivador, emojis moderados.
```

---

# CRTR ‚Äì Ejemplo 3

Este prompt estructura la descripci√≥n de un Pull Request para facilitar la revisi√≥n y auditor√≠a.  
Incluye contexto t√©cnico, rol del revisor, tarea concreta y formato detallado, ayudando a que la informaci√≥n cr√≠tica sea clara y organizada.

```text
Context: Migraci√≥n de ‚Äúuser-auth‚Äù a TS 5.5 estricto.  
Role: Revisor/a Front-End principal.  
Task: Redactar descripci√≥n de Pull Request incluyendo riesgos y pruebas.  
Result: Markdown con secciones: Contexto, Cambios, Pruebas, Checklist QA.
```

---

# CRTR ‚Äì Recursos

- Plantilla r√°pida:

```text
Context: ‚Ä¶  
Role: ‚Ä¶  
Task: ‚Ä¶  
Result: ‚Ä¶
````

* [LearnPrompting ‚Äì Prompt Structure & Key Parts](https://learnprompting.org/docs/intro/prompt-structure)
  Gu√≠a completa para entender y construir prompts efectivos.

* [DAIR AI ‚Äì Prompt Engineering Guide](https://www.dair.ai/guide/prompt-engineering)
  Recurso detallado con t√©cnicas y mejores pr√°cticas para prompt engineering.

* [OpenAI Cookbook ‚Äì Prompt Best Practices](https://github.com/openai/openai-cookbook/blob/main/examples/Prompt_Best_Practices.ipynb)
  Colecci√≥n de ejemplos y consejos oficiales para mejorar la interacci√≥n con modelos OpenAI.

* [ChatGPT Prompt Engineering for Developers (deeplearning.ai)](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
  Curso pr√°ctico para aprender t√©cnicas de prompting aplicado a desarrolladores.

---

# Muchas gracias

### Germ√°n Aliprandi

üìß galiprandi@gmail.com

üîó [linkedin.com/in/galiprandi](https://linkedin.com/in/galiprandi)
